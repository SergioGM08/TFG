\chapter{Fundamentos Teóricos} \label{Capitulo 2}

En este capítulo nos centraremos en 

\section{Fundamentos Estadísiticos}

\subsection{Espacios de probabilidad y variables aleatorias}

Dado un experimento, recibirá el nombre de {\sl espacio muestral}, $\mathbf{\Omega}$, el conjunto de todos los posibles resultados de dicho experimento. Cada uno de esos posibles resultados se denomina {\sl suceso elemental}, mientras que un subconjunto de más de un elemento y sus uniones se llaman {\sl sucesos compuestos}. El espacio muestral puede ser de tipo {\sl finito} (lanzamiento de un dado), de tipo {\sl infinito numerable} (lanzamiento de una moneda hasta obtener la primera cruz) o de tipo {\sl continuo} (posición de una partícula en desplazamiento en el plano) \cite{paloma1988lecciones}.

Sea $\mathscr{A}$ una colección no vacía de subconjuntos del espacio muestral $\mathbf{\Omega}$. Cada elemento $\textit{A}$ de $\mathscr{A}$ se trata de un {\sl suceso}, con su correspondiente probabilidad. Por ejemplo, ``salir par en el lanzamiento de un dado'', con probabilidad $\dfrac{1}{2}$. Puede ser que sea un suceso {\sl imposible}, $\emptyset$, como sacar un 7 en el lanzamiento de un dado, o un suceso {\sl incompatible} (intersección nula entre los sucesos), como sacar par e impar a la vez. Denotando las {\sl partes} de $\mathbf{\Omega}$ como $\mathscr{P}(\mathbf{\Omega})$, todos los subconjuntos posibles del espacio muestral, se tiene que $\mathscr{A} \subseteq
\mathscr{P}(\mathbf{\Omega})$. Por lo general, se exigirá tener una estructura de {\sl $\sigma$-álgebra}. Así, $\mathscr{A}$ tiene dicha estructura si y sólo si:
\begin{enumerate}
    \item $\mathbf{\Omega} \in \mathscr{A}$.
    \item $\forall A \in \mathscr{A}, \text{ se tiene que } A^{c} \in \mathscr{A}$.
    \item Para toda colección numerable $\{A_n\}_{n\in\mathbb{N}} \subset \mathscr{A}, \text{ se tiene que } \displaystyle\bigcup_{n=1}^{\infty} A_n \in \mathscr{A}$.
\end{enumerate}

Sea la terna ($\mathbf{\Omega}, \mathscr{A}, P$), de espacio muestral $\Omega$, $\sigma$-álgebra $\mathscr{A}$ sobre $\mathbf{\Omega}$, y una medida de probabilidad $P$ sobre $\mathscr{A}$, un {\sl espacio probabilístico}. Sea la dupla ($\mathbb{R}, \mathbb{B(\mathbb{R})}$), con $\mathbb{R}$ la recta real y $\mathbb{B(\mathbb{R})}$ la $\sigma$-álgebra de Borel, generada por la clase de todos los intervalos de $\mathbb{R}$ (si $\mathscr{C}$ = $\{(a, b)\}$, se tiene que $(a, b) = \displaystyle\bigcup_{n=1}^{\infty} \left(a, b - \frac{1}{n}\right]$), un {\sl espacio probabilizable} o {\sl espacio medible}. Sea la función:

\begin{equation*}
\begin{split}
    X : \Omega \rightarrow{\mathbb{R}} \\
    w \mapsto X(w)
\end{split}
\end{equation*}

con $w \in A$. Dicha función será {\sl variable aleatoria} si y sólo si $X^{-1}(w) \in \mathscr{A}, \forall B \in \mathbb{B(\mathbb{R})}$.

Una {\sl medida de probabilidad} $P$ se caracteriza mediante una función, llamada {\sl función de distribución}, tal que $F : \mathbb{R} \rightarrow{\left[0,1\right]}$, cumpliendo que sea monótona no decreciente, es decir, $F(x_1) \leq F(x_2), \textbf{ si }x_1 < x_2$, que sea continua por la derecha, esto es, $\forall x \in \mathbb{R}, F(x) = \displaystyle\lim_{y \to x} F(y)$ y, además, se verifica que$\displaystyle\lim_{x \to -\infty} = 0$ y $ \displaystyle\lim_{x \to \infty} = 1$.

\subsection{Distribuciones de probabilidad relevantes}
Dentro de las numerosas {\sl distribuciones de probabilidad} existentes, se definirán las siguientes:

{\bf Distribución uniforme}: una variable aleatoria $X$ se dice uniforme en $\left(a, b\right)$ $\left(X \sim U\left(a, b\right)\right)$ si su {función de densidad} es de la forma
\begin{equation*}
    f(x) = \dfrac{1}{b-a}I_{\left(a, b\right)}(x)
\end{equation*}
Su uso es frecuente para la generación de números {\sl pseudoaleatorios}, debido a su sencillez computacional. Se trata de una distribución de tipo continuo.

{\bf Distribución normal} (también conocida como \textsl{gaussiana}): una variable aleatoria $X$ sigue esta distribución, con media $\mu$ y varianza $\sigma^2$ (-$\infty < \mu < \infty;\, \sigma > 0$; $X \sim \mathcal{N}\left(\mu, \sigma\right)$) si $X$ es continua con función de densidad
\begin{equation*}
    f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2} \left(\frac{x - \mu}{\sigma}\right)^2}
    \quad \text{para } -\infty < x < \infty
\end{equation*}
Es una distribución común en inferencia estadística y en heurísticas que modelan procesos estocásticos, ya que, por el {\sl Teorema Central del Límite} \ref{tma cent lim}, con cierto número de muestras, se puede trabajar bajo hipótesis de normalidad. Se trata de una distribución de tipo continuo.

{\bf Distribución exponencial}: esta distribución está ligada a fenómenos de espera, como distribución de probabilidad del tiempo que tarda en ocurrir un suceso. Una variable aleatoria se distribuye de manera exponencial, con parámetro $\theta > 0$ $\left(X \sim Exp\left(\theta\right)\right)$, si su función de densidad es
\begin{equation*}
    f(x) = \theta e^{-\theta x} I_{(x>0)}(x)
    \label{eq:exponential_distribution}
\end{equation*}
Se trata de una distribución también de tipo continuo.

{\bf Distribución de Bernoulli}: un experimento Bernoulli consta de sólo dos posibles resultados en cada realización, denotando $p$ como éxito y $q = 1 - p$ como fracaso. Una variable aleatoria sigue una distribución de Bernoulli de parámetro $p$ $\left(X \sim BE\left(p\right)\right)$ si su {\sl función de masa} es de la forma
\begin{equation*}
    P(X = x) = p^x (1-p)^{1-x}, \quad x \in \{0, 1\}
    \label{eq:bernoulli_distribution}
\end{equation*}

{\bf Distribución Binomial}: repitiendo un experimento de tipo Bernoulli $n$ veces, siendo cada repetición independiente del resto, la variable aleatoria $X=x$ representa el número de éxitos totales. Si para cada repetición tenemos una variable aleatoria $X_i,\, \forall i \in \{1, \dots, n\}$, de forma que $X_i = 1$\,, si se ha tenido éxito en la $i$-ésima repetición,  $X_i = 0$\, en caso contrario, y definimos $X = \displaystyle\sum_{i=1}^{n}X_i$, dicha variable aleatoria sigue una distribución binomial si
\begin{equation*}
P(x; n, p) = 
\begin{cases} 
    \binom{n}{x} p^x (1-p)^{n-x} \quad & x = 0, 1, 2, \ldots, n \\ 
    0 & \text{en otro caso} \,(0 \leq p \leq 1,  n \in \mathbb{Z}).
\end{cases}
\label{eq:binomial_distribution}
\end{equation*}

\subsubsection{Conceptos de estadística inferencial}

{\bf Muestra}: en este contexto, una variable aleatoria $X$ se conoce como \textsl{población}. Dada una población $X$, una \textsl{m.a.s.} de tamaño $n$, es la repetición de $X_1, X_2, \dots, X_n$ de variables aleatorias independientes entre sí, con distribución igual a la de $X$.

{\bf Esperanza}: se trata del promedio ponderado. Si la variable aleatoria es discreta, con $p_k = P\left(X = x_k\right)$, siendo $k \geq 1, \dots\,$ como función de masa, y se verifica que $\displaystyle\sum_{k = 1}^{\infty} \abs{x_k}\cdot p_k < \infty$, la {esperanza matemática} de la variable aleatoria se define como:
\begin{equation*}
    \mu = E(X) = \sum_{k=1}^{n} x_k \cdot p_k
    \label{eq:expected_value_dis}
\end{equation*}
Si es una variable aleatoria continua, con función de densidad $f(x)$ y sucede que $\displaystyle\int_{-\infty}^{\infty} \abs{x}\cdot f(x) \, dx < \infty$, entonces la esperanza matemática se define como:
\begin{equation*}
    \mu = E(X) = \int_{-\infty}^{\infty} x\cdot f(x) \, dx
    \label{eq:expected_value_cont}
\end{equation*}

{\bf Media, varianza y desviación estándar}: ...


\subsubsection{Muestreo y convergencia}

{\bf Convergencia casi segura}: una sucesión de variables aleatorias $\{ X_n : n \geq 1 \}$ converge \textsl{casi seguro} a una variable aleatoria $X$, denotándose como $X_n \xhookrightarrow{^{c.s.}} X$, si y sólo si:
\begin{equation*}
    \displaystyle P\left(w \in \Omega : \lim_{n\rightarrow{\infty}} X_{n}(w) = X(w) \right) = 1
    \label{eq:cs}
\end{equation*}

{\bf Ley Fuerte de los Grandes Números}: una sucesión de variables aleatorias $\{ X_n : n \geq 1 \}$ obedece dicha ley, respecto de una sucesión de constantes de normalización $\{ B_n : n \geq 1 \}$, con $B_n > 0$ y $B_n \rightarrow{\infty}$, si existe una sucesión de constantes de centralización, reales, $\{A_n : n \geq 1 \}\,$, tal que:
\begin{equation*}
    \dfrac{S_n - A_n}{B_n}\xhookrightarrow{^{c.s.}}0 \,, \text{cuando } n\rightarrow{\infty}.
\end{equation*}
De aquí se deduce que, al promediar varias simulaciones, se mejora la evaluación de los valores esperados.

{\bf Teorema Central del Límite} \label{tma cent lim}: Sea $X_1, X_2, \dots\,$ una sucesión de variables aleatorias independientes e idénticamente distribuidas (en adelante, v.a.i.i.d.), cuyas funciones generatrices de momentos existen centradas en 0. Sea $E(X_i) = \mu \text{ y } Var(X_i) = \sigma^2 > 0$. Definimos la {\sl media muestral} como $\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$. Además, sea $G_n(x)$ la función de distribución de $\frac{\sqrt{n}(\bar{X_n} - \mu)}{\sigma}$. Así, para todo real $x \in \mathbb{R}$, se tiene:
\begin{equation*}
    \lim_{n \rightarrow \infty} G_n(x) = \int_{-\infty}^{x} \dfrac{1}{\sqrt{2\pi}} e^{-x^2/2} \, dx
\end{equation*}
Lo que resulta en la convergencia a la distribución $\sqrt{n}\dfrac{\bar{X_n} - \mu}{\sigma} \xrightarrow{d} \mathcal{N}\left(0, 1\right)$.

{\bf Muestreo aleatorio}: dependiendo del método seguido para la extracción de la muestra, puede ser de los siguientes tipos:
\begin{itemize}
    \item {\bf Muestreo con reemplazamiento}: la elección de cada miembro de la población es equiprobable. Si el tamaño de la población es $N$, cada muestra tiene probabilidad $\dfrac{1}{N}$. Es de uso frecuente cuando la población no se compone de elementos tangibles, como la concentración de una sustancia en una disolución. Se repite la observación $n$ veces, obteniendo $X_n$ observaciones. También, si la población consta de elementos tangibles, se seleccionan $n$, extrayendo cada uno de ellos, observándolo y devolviéndolo a la población, acabando así en $P\left(X_1 = x_1, X_2 = x_2, \dots,\, X_n = x_n\right) = \dfrac{1}{N^n}$.
    \item {\bf Muestreo sin reemplazamiento}: se extraen $n$ elementos de la población $N$, pero, tras la observación de cada uno de ellos, no se devuelven.
    
    Así, $P\left(X_1 = x_1\right) = \dfrac{1}{N};\,$ y $P\left(X_2 = x_2 / X_1 = x_1\right) = \dfrac{1}{N-1}\,$, si $x_2 \neq x_1$ y 0 en otro caso.
\end{itemize}

Tras estas definiciones, si queremos obtener una muestra aleatoria simple (m.a.s.) de tamaño $n$, sólo ocurrirá si se realiza un muestreo con reemplazamiento. Sin embargo, si $N$ es lo bastante grande, ambos procedimientos, con reemplazo y sin reemplazo, acabarán dando probabilidades casi exactas: una, $\dfrac{1}{N}$, y otra, $\dfrac{1}{N-1}$.

\subsubsection{Métodos de simulación y aproximación}

{\bf Simulación de Monte-Carlo}:

{\bf Método de aceptación-rechazo}:


{\bf Cadenas de Markov}: sea una colección de variables aleatorias $X_1, X_2,\, \dots,\,X_n$. Tomando $X_i$ como el estado del sistema en el momento $i$, si los posibles valores de $X_i$ (estados del sistema), van desde 1 hasta $N$ y hay un conjunto $p_{ij}$ con $i, j \in \{1, \dots, N\}$ de números positivos menores que 1 tales que denotan la probabilidad de transitar del estado $i$ al estado $j$, entonces la colección $\{X_n, \,n\geq 1\}$ se conoce como \textsl{cadena de Markov} \cite{ross2022simulation}.

\newline
\textcolor{red}{OPTIMIZACIÓN A PARTIR DE AQUÍ}\\\\


\section{Optimización Heurística}
La {\sl optimización matemática} es una técnica de investigación operativa utilizada en la toma de decisiones. El campo de la investigación operativa se sirve, además, de otras herramientas, como la estadística, la teoría de la probabilidad, la simulación, y el análisis de decisiones.

En particular, la optimización matemática, en su búsqueda de la mejor solución posible a un problema, requiere de tres elementos:
\begin{itemize}
     \item {\bf Modelo de optimización}: constituido de variables de decisión, restricciones y funciones objetivo.
    \item {\bf Datos}: para las demandas del modelo.
    \item {\bf Algoritmo}: para resolver la instancia del modelo.
\end{itemize}
Con ello, se buscan los valores de las variables de decisión que satisfagan todas las restricciones y que optimicen las funciones objetivo.

\subsection{Problemas de optimización}
Para plantear un {\sl problema de optimización}, hay que definir los elementos anteriormente citados.

Las {\bf variables de decisión} en un modelo de optimización representan los parámetros variables del problema. Sus valores varían según marque el algoritmo, con el fin de obtener aquellos que mejor se ajusten a las funciones objetivo.
Los aspectos más relevantes de estas variables son, el {\sl dominio} al cual pertenecen, los {\sl límites} entre los que se disponen (y que son delimitados por la frontera del dominio) y, finalmente, el {\sl tipo} de variable, ya que puede ser real, entero, booleano, etc.
Es importante hacer una elección coherente de estas características, pues ejerce un serio impacto en la redacción de las restricciones, la elección del algoritmo y, por tanto, en los resultados obtenidos.

Las {\bf restricciones} representan los límites del conjunto de soluciones que se está dispuesto a admitir. Se elaboran mediante relaciones entre las variables de decisión, así como entre sus valores.

Las {\bf funciones objetivo} en un modelo de optimización son representaciones matemáticas del ámbito que se desea optimizar. Estas funciones pueden ser {\sl maximizadas} o {\sl minimizadas}, y su tratamiento, ya sea individual o combinado en problemas con múltiples objetivos, determina el tipo de algoritmo de optimización.

Una vez sentados estos elementos y finalizado el algoritmo, se llega a la {\bf solución} del problema, la cual puede ser una combinación de solución {\sl factible} (satisface las restricciones), {\sl óptima} (factible que alcanza el mejor valor posible), {\sl no factible} (fuera de la región factible, por lo que viola alguna restricción), y {\sl no acotada} (tiende a más o a menos infinito en maximización y en minimización, respectivamente).

Más formalmente, sea $\vFact$ el vector de $N$ variables de decisión del sistema, $\Omega$ el espacio sobre el cual están definidas las soluciones factibles, \textit{$f_i$}(\vFact) cada una de las \textit{O} funciones objetivo del problema, y optG($\cdot$) el método para conjuntar y optimizar los objetivos de manera sincrónica.
A su vez, el espacio $\Omega$ queda definido por el tipo \textit{\textbf{T}} de cada variable, y las relaciones $g_j$(\vFact), $h_k$(\vFact) que definen las restricciones del problema:

\begin{figure}[h]
    \begin{minipage}[c]{0.45\linewidth}
        \vspace{0.2em} % Ajusta este valor para que ambos bloques queden alineados
        \begin{equation*}
            \begin{aligned}
                \text{optG}&\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right) \\
                &\vFact = [x_1, x_2, \dots, x_N] \\
                &\vFact \in \Omega
            \end{aligned}
        \end{equation*}
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\linewidth}
        \begin{equation*}
            \vFact \in \Omega =
            \begin{cases}
                x_i \in T_i \\
                g_j(\vFact) \leq 0, \, j=1..R \\
                h_k(\vFact) = 0, \, k=1..P
            \end{cases}
        \end{equation*}
    \end{minipage}
\end{figure}

Existen, entre los métodos de combinación y optimización simultánea, dos grandes familias a destacar:
\begin{itemize}
    \item Los métodos que convierten un problema con $\textit{O}>1$ objetivos en sólo un problema mediante una {\sl combinación} (a menudo, lineal) de todos los objetivos y que optimizan el valor combinado, como, por ejemplo, $\displaystyle \min\limits_{\vFact} \sum_{i=1}^{O} w_i f_i(\vFact)$.
    \item Los métodos que optimizan de forma {\sl simultánea} todos los objetivos del problema utilizando una definición en la que se establece si una solución es mejor que otra, comparando cada uno de los objetivos por separado. Por ejemplo, con la definición de {\sl Pareto optimalidad}, una solución \textbf{A} es mejor que una solución \textbf{B} si para todo \textit{i}, $f_i\left(\textbf{A}\right)$ no es peor que $f_i\left(\textbf{B}\right)$, y existe un $j$ tal que $f_j\left(\textbf{A}\right)$ es mejor que $f_j\left(\textbf{B}\right)$. Este procedimiento se conoce como {\sl frentes Pareto} de soluciones igualmente óptimas.
\end{itemize}

Hay que remarcar que los problemas {\sl monoobjetivo} con un solo objetivo son un caso particular de los problemas {\sl multiobjetivo} con objetivos múltiples, y eb ellos no es estrictamente necesario el uso de una función G($\cdot$).

Más definiciones formales de los problemas de optimización son:
\begin{itemize}
    \item {\bf Vector de decisión factible}: vector $\vFact$ que cumple las restricciones, es decir, $\vFact \in \Omega$.
    \item {\bf Óptimo local}: un vector de decisión factible $\vFactOpt$ representa un {\sl óptimo local} de la función G$\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right)$ si existe $\varepsilon>0$ tal que G$\left(f_1(\vFactOpt), f_2(\vFactOpt), \dots, f_O(\vFactOpt)\right)$ no es peor que G$\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right)$, $\forall \vFact$ en el entorno $\left\lVert \vFact-\vFactOpt \right\rVert<\varepsilon$.
    \item {\bf Óptimo global}: un vector de decisión factible $\vFactOpt$ representa un {\sl óptimo global} de la función G$\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right)$ si G$\left(f_1(\vFactOpt), f_2(\vFactOpt), \dots, f_O(\vFactOpt)\right)$ no es peor que G$\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right)$, $\forall \vFact \in \Omega$.
    \item {\bf Punto de silla}: un vector de decisión factible $\vFactOpt = \left[\vFactOpt_A, \vFactOpt_B\right]$ representa un {\sl punto de silla} de la función G$\left(f_1(\vFact), f_2(\vFact), \dots, f_O(\vFact)\right)$ si existe $\varepsilon>0$ tal que G$(f_1(\left[\vFact_A, \vFactOpt_B\right]),$ $f_2(\left[\vFact_A, \vFactOpt_B\right]), \dots, f_O(\left[\vFact_A, \vFactOpt_B\right]))$ no es peor que G$(f_1\left(\left[\vFactOpt_A, \vFactOpt_B\right]\right), f_2\left(\left[\vFactOpt_A, \vFactOpt_B\right]\right), \dots,$\\ $f_O\left(\left[\vFactOpt_A, \vFactOpt_B\right]\right))$, y éste, a su vez, no es peor que G$(f_1\left(\left[\vFactOpt_A, \vFact_B\right]\right), f_2\left(\left[\vFactOpt_A, \vFact_B\right]\right), \dots,$ $f_O\left(\left[\vFactOpt_A, \vFact_B\right]\right))$, $\forall\vFact$ en $\left\lVert \left[\vFact_A, \vFact_B\right]-\left[\vFactOpt_A, \vFactOpt_B\right] \right\rVert<\varepsilon$.
\end{itemize}

En cuanto a los problemas, atendiendo a distintos criterios, se pueden clasificar según:
\begin{enumerate}
    \item {\bf Existencia de restricciones}:
        \begin{enumerate}
            \item {\sl Sin restricciones}: en $\Omega$ sólo se define el tipo de variable.
            \item {\sl Con reestricciones}: en $\Omega$ se definen restricciones $g_j(\vFact)\leq 0$, o $h_k(\vFact)=0$.
        \end{enumerate}
    \item {\bf Naturaleza de las variables de decisión}:
        \begin{enumerate}
            \item {\sl Estáticos}: la variable tiempo no es relevante.
            \item {\sl Dinámicos}: el tiempo es la variable de la que dependen el resto de variables.
        \end{enumerate}
    \item {\bf Número de objetivos}:
        \begin{enumerate}
            \item {\sl Mono-objetivo}: se optimiza un sólo objetivo.
            \item {\sl Multi-objetivo}: se optimizan varios objetivos.
        \end{enumerate}
    \item {\bf Naturaleza de las funciones involucradas}:
        \begin{enumerate}
            \item {\sl Problemas lineales}: todas las funciones objetivo de las restricciones son lineales.
            \item {\sl Problemas no lineales}: alguna de las funciones objetivo o restricciones no es lineal.
            \item {\sl Problemas de programación geométrica}: las funciones objetivo y las restricciones son expresables en forma de polinomios de las variables de decisión.
            \item {\sl Problemas cuadráticos}: caso especial de problema no lineal en el que las funciones objetivo son cuadráticas y las restricciones son lineales.
        \end{enumerate}
    \item {\bf Valores permisibles de las variables de decisión}:
        \begin{enumerate}
            \item {\sl Problemas de programación reales}: las variables de decisión toman cualquier valor real.
            \item {\sl Problemas de programación entera}: las variables de decisión toman sólo valores enteros (o discretos). Como caso particular, se tienen las de variable booleana (0 ó 1).
            \item {\sl Problemas de programación mixta}: una mezcla de los anteriores.
        \end{enumerate}
    \item {\bf Naturaleza determinista de las variables de decisión}:
        \begin{enumerate}
            \item {\sl Problemas deterministas}: todos los parámetros del problema se conocen con certeza y, por tanto, se pueden evaluar las funciones.
            \item {\sl Problemas estocásticos}: existe incertidumbre sobre alguno o todos los parámetros del problema, y se tienen que dar definiciones probabilísticas para algunas funciones.
        \end{enumerate}
    \item {\bf Separabilidad de las funciones}:
        \begin{enumerate}
            \item {\sl Problemas separables}: tanto las funciones objetivo como las restricciones pueden separarse en suma de funciones de diferentes variables de decisión. Si la suma se realiza de manera independiente sobre cada una de las variables de decisión, se dice que los problemas son {\sl totalmente separables}.
            \item {\sl Problemas no separables}: caso contrario al anterior.
        \end{enumerate}
    \item {\bf Complejidad computacional}:
        \begin{enumerate}
            \item {\sl Problemas de clase P}: se conocen algoritmos capaces de obtener la solución óptima del problema en un tiempo polinomial, según el tamaño del problema. Se suele expresar como $O(p(n))$, con $n$ el tamaño, $p(\cdot)$ un polinomio, y $O(\cdot)$ su orden de complejidad.
            \item {\sl Problemas de clase NP}: un algoritmo no puede resolverlo en tiempo polinomial, o bien no se conoce. A su vez, pueden ser {\sl NP-hard} o {\sl NP-completos}. Existen dos vías para enfrentar estos problemas: o bien utilizar un algoritmo que asegure la optimalidad pero el tiempo de cómputo sea excesivo, o bien encontrar una solución no óptima pero aceptable, en un tiempo razonable.
        \end{enumerate}
\end{enumerate}
En este último criterio, los algoritmos del primer grupo se conocen como {\sl exactos}, y los del segundo grupo, {\sl aproximados}. Algunos de estos algoritmos aproximados se los denominan {\sl heurísticos}.

\section{Algoritmos Heurísticos}
En inteligencia artificial, el término {\sl heurístico} hace referencia, en especial, a un procedimiento que intenta aportar soluciones, razonablemente buenas, teniendo en cuenta la calidad de las soluciones y los recursos empleados. En investigación operativa es similar, pero no se asegura la optimalidad ni la factibilidad de las soluciones, así como tampoco lo cerca de ellas que se está. También se usa el término {\sl heurística} cuando se realizan modificaciones en el procedimiento de la solución en pos de mejorar su rendimiento.

En el contexto de las {\sl metaheurísticas}, este término se utiliza para referirse a algoritmos heurísticos que integran un conjunto de mecanismos de control diseñados para optimizar el funcionamiento de la heurística, y mejorar así su rendimiento. Otra acepción sería un algoritmo basado en procedimientos
heurísticos “inteligentes”.

Las propiedades que se desea que posean estos algoritmos son {\sl sencillez}, {\sl precisión} (sin ambigüedades), {\sl eficiencia} (da soluciones de alta calidad y se aprovechan los recursos), {\sl generalidad} (aplicable a muchos problemas), {\sl robustez} (su comportamiento apenas varía con modificaciones o cambio de contexto), {\sl multiplicidad de soluciones} (a elección del usuario), {\sl flexibilidad} en los parámetros y restricciones y, finalmente, {\sl maleabilidad} (para particularidades y generalidades de cada problema). 

Atendiendo al modo en el que buscan y construyen sus soluciones, las cuatro grandes familias son:
\begin{enumerate}
    \item {\bf Metaheurísticas de relajación}:  se resuelven versiones menos restrictivas y, por tanto, más fáciles de resolver que el problema original.
    \item {\bf Metaheurísticas constructivas}: se obtiene la solución del problema a partir del análisis y selección gradual de las componentes que la forman.
    \item {\bf Metaheurísticas de búsqueda}: se recorre el espacio de soluciones mediante transformaciones y movimientos que aprovechan la estructura del problema.
    \item {\bf Metaheurísticas evolutivas}: los valores de un conjunto de soluciones evolucionan de forma paralela, acercándose según aumenta el número de iteraciones, a la solución óptima.
\end{enumerate}

\subsection{Metaheurísticas de búsqueda} \label{subsec:2.3.1}
Las {\sl metaheurísticas de búsqueda} establecen estrategias para recorrer el espacio de soluciones del problema, transformando de forma iterativa, y a través de reglas astutas, una solución inicial en otra.

A su vez, hay dos grandes familias: las {\sl técnicas de búsqueda local} y las {\sl técnicas de búsqueda global}.

Por un lado, las {\sl técnicas de búsqueda local} se basan en alguna regla inteligente que modifica una solución del problema. Ésta se aplica de forma iterativa hasta que no se pueda mejorar la solución previa.
Las modificaciones sólo permiten trasladar una solución actual a una de su vecindad. Se dejarán de realizar estas modificaciones si no se encuentra ninguna solución mejor que la de partida. Si la hubiera, se utilizará la mejor solución hallada para la solución de partida de la siguiente iteración.
Este tipo de técnicas están relacionadas con {\sl algoritmos de búsqueda monótona} o con {\sl técnicas de escalado} (\textit{hill-climbing}). Además, al elegir la mejor solución posible determinada por la regla elegida, convierte estas metaheurísticas en {\sl algoritmos voraces} (\textit{greedy}).
La desventaja primordial de las búsquedas locales es que pueden quedar fácilmente ``atrapadas'' en un {\sl óptimo local}. Esto es, no puede mejorarse una solución mediante las transformaciones de la heurística.

Por otro lado, las {\sl metaheurísticas de búsqueda global} pretenden eliminar la localidad extendiendo la búsqueda de los algoritmos a otras regiones del espacio. Esto se consigue mediante varias mecánicas, como son las {\sl búsquedas de arranque múltiple} (\textit{Multi Start Search}), en las que se reinicia la búsqueda a partir de otra solución inicial distinta; las {\sl búsquedas por entorno variable} (\textit{Variable Neighbourhood Search, VNS}), en las que se modifica el tipo de movimiento en el entorno definido por la regla para evitar quedar atrapada en una región rígida; {\sl búsquedas no monótonas}, en las que se admite que el movimiento empeore durante la búsqueda, ya sea utilizando memoria para que con la información adquirida no se caiga en una zona concreta del espacio, evitando momentáneamente soluciones muy parecidas entre sí, como en la {\sl búsqueda tabú} (\textit{Taboo Search, TS}), o bien se establezcan normas para controlar la probabilidad de aceptar una solución igual o peor, como en el {\sl enfriamiento simulado} (\textit{Simulated Annealing}), en el que la probabilidad de aceptación viene dada por una función exponencial del empeoramiento producido.

\subsection{Metaheurísticas evolutivas}
Las {\sl metaheurísticas evolutivas} establecen estrategias para guiar la evolución de un conjunto de posibles soluciones, al que llamaremos {\sl población}, hacia la solución óptima.

La exploración del espacio de soluciones se hace en cada iteración con una población, modificando cada individuo teniendo en cuenta los valores del resto y las funciones de ajuste asociadas. Esto último no es estrictamente necesario, pues habrá regiones no explorables con la información exclusiva de la población, por lo que se pueden añadir mecanismos adicionales. En cada iteración, se sustituye la población con nuevas soluciones y, en ocasiones, parte de las ya existentes. En algunos algoritmos se guardarían los mejores individuos para tenerlos en cuenta posteriormente. La distinción entre metaheurísticas evolutivas se hace respecto a cómo combinan la información obtenida de la población.

Entre otros, existen tres grandes grupos:

{\bf Algoritmos genéticos} (\textit{Genetic Algorithms, GA}), en los que, en cada iteración (generación), mantiene una población de posibles soluciones que evolucionan hacia las soluciones óptimas del problema mediante una selección de individuos (selección natural) y operadores genéticos (cruce y mutación). Se inspira en la teoría de la evolución de Darwin.

{\bf Nubes de partículas} (\textit{Particle Swarm Optimization, PSO}), en las que se mantiene un conjunto de posibles soluciones (partículas) que son desplazadas por el espacio de búsqueda teniendo en cuenta el desplazamiento anterior, el mejor valor hallado por la partícula (líder o mejor local), y el mejor valor hallado por todas las partículas (líder o mejor global). Está inspirado en el comportamiento de bandadas de aves o bancos de peces.

{\bf Evolución diferencial} (\textit{Differential Evolution, DE}), en la que, a lo largo de las iteraciones, el conjunto de posibles soluciones son desplazadas incrementalmente (diferencial) teniendo en cuenta las diferencias entre pares de soluciones del conjunto, adaptándose a la diversidad de soluciones existentes. Los métodos de escalada o gradiente son de este estilo.





